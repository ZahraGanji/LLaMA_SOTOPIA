import pandas as pd
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
import torch
from prompts_json import  generate_episode

# Load the model and tokenizer for generating the episodes
MODEL_NAME = "meta-llama/Meta-Llama-3-70B-Instruct"

# MODEL_NAME = "meta-llama/Meta-Llama-3-8B-Instruct"
# MODEL_NAME = "meta-llama/Llama-2-70b-chat-hf"
# MODEL_NAME = "microsoft/Phi-3-mini-4k-instruct"
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

quant_config = BitsAndBytesConfig(
    load_in_4bit=False,                # Switch to 8-bit quantization
    bnb_4bit_quant_type="nf4",         # Keep this, but it only applies to 4-bit, so no longer relevant here
    bnb_4bit_use_double_quant=True,    # Enable double quantization
    bnb_4bit_compute_dtype=torch.float32  # Use higher precision for computations
)


model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map="auto", quantization_config=quant_config)
# model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map="auto")
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

# Define the JSON schema for generating episodes
json_schema_episode = {
    "type": "object",
    "properties": {
        "social_interaction": {"type": "string"},
    },
    "required": ["social_interaction"]
}

# Function to extract episode data and generate episodes
def extract_and_generate_episodes(csv_file):
    # Load the CSV data into a pandas DataFrame
    df = pd.read_csv(csv_file)
    
    social_interaction_list = []
    # Loop through each row in the CSV to extract the fields and generate episodes
    for index, row in df.iterrows():
        title = row['movie_scene.name']  # Movie scene title
        interaction_type = row['interaction_type']
        scenario_description = row['movie_scene.scenario']
        character1 = row['movie_scene.character1']
        character2 = row['movie_scene.character2']
        goals1 = row['movie_scene.goal1']
        goals2 = row['movie_scene.goal2']
        relationship = row['movie_scene.relationship']


        # Generate the episode using the extracted fields
        social_interaction = generate_episode(
            title, title, interaction_type, scenario_description, 
            character1, character2, goals1, goals2,relationship, 
            model, tokenizer, json_schema_episode, max_length=50
        )
        
        social_interaction_list.append(social_interaction)

        print(f"Generated episode for row {index}: {social_interaction}")

    # Add the generated episodes (Agent A and Agent B) as new columns in the original DataFrame
    df['social_interaction'] = social_interaction_list
    # Save the updated DataFrame back to the same CSV file
    df.to_csv(csv_file, index=False)
    print("Episodes have been added to the CSV file.")

# Call the function and generate episodes, updating the CSV file in-place
csv_file = './pipeline_llama_new_8B.csv'  # Path to the CSV file generated by the previous script
extract_and_generate_episodes(csv_file)
